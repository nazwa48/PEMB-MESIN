{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T22ueImYnFF"
      },
      "source": [
        "## **Jobsheet 10 | Pertemuan 10**\n",
        "----\n",
        "\n",
        ">### Data Mahasiswa\n",
        "><p>Nama : Nazwa Ayunda Mirrohillah<p>\n",
        ">Kelas : 3C<p>\n",
        ">Nim : 2141720013<p>\n",
        ">Prodi : D-IV Teknik Inormatika<p>\n",
        ">Jurusan : Teknologi Inormasi<p>\n",
        "\n",
        "----\n",
        "## **Recurent Neural Network (RNN)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dighPNItqrOf"
      },
      "source": [
        "### **Tugas**\n",
        "\n",
        "Prosedur pelatihan pada praktikum 2 merupakan prosedur sederhana, yang tidak memberi Anda banyak kendali. Model ini menggunakan \"teacher-forcing\" yang mencegah prediksi buruk diumpankan kembali ke model, sehingga model tidak pernah belajar untuk pulih dari kesalahan. Jadi, setelah Anda melihat cara menjalankan model secara manual, selanjutnya Anda akan mengimplementasikan custom loop pelatihan. Hal ini memberikan titik awal jika, misalnya, Anda ingin menerapkan pembelajaran kurikulum untuk membantu menstabilkan keluaran open-loop model. Bagian terpenting dari loop pelatihan khusus adalah fungsi langkah pelatihan.<p>\n",
        "Gunakan tf.GradientTape untuk men track nilai gradient. Anda dapat mempelajari lebih lanjut tentang pendekatan ini dengan membaca eager execution guide.<p>\n",
        "\n",
        "Prosedurnya adalah \"<p>\n",
        "1. Jalankan Model dan hitung loss dengan tf.GradientTape.\n",
        "2. Hitung update dan terapkan pada model dengan optimizer\n",
        "\n",
        "\n",
        "### **Jawab**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m1dVe8FxrDuU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGsqYujLrDdY"
      },
      "source": [
        "melakukan download Dataset Shakespeare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuuPhTEFrWgL",
        "outputId": "dd3e1f3c-09a3-43e8-b171-f711b920dee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UMseXEHn55d"
      },
      "source": [
        "Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alMtjR79rbPZ",
        "outputId": "02ba1694-ea06-41e7-8ac0-0ad4d3448f14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ],
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KW3eyB9cre6X",
        "outputId": "7f8ac394-2757-4065-c285-5b4994c579b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYzdGYDnrouC",
        "outputId": "805638c4-02a6-484a-a1c4-a14f9cedf7a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65 unique characters\n"
          ]
        }
      ],
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dp8Pf68CpXXJ",
        "outputId": "cdfad7cd-e446-4dca-eb9a-5ce748b0c06f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "   ! $ & ' , - . 3 : ; ? A B C D E F G H I J K L M N O P Q R S T U V W X Y Z a b c d e f g h i j k l m n o p q r s t u v w x y z "
          ]
        }
      ],
      "source": [
        "# Print unique characters\n",
        "for char in vocab:\n",
        "    print(char, end=' ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sJzZUuCpiu6"
      },
      "source": [
        "olah Teks\n",
        "\n",
        "Vectorize Teks\n",
        "\n",
        "Sebelum training, Anda perlu mengonversi string menjadi representasi numerik. tf.keras.layers.StringLookup dapat mengubah setiap karakter menjadi ID numerik. Caranya adalah teks akan dipecah menjadi token terlebih dahulu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TndF_SUbps7q",
        "outputId": "93bb796e-4ccd-4fb1-b2ec-de290fae0e4f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7PmP0wrpwLx"
      },
      "source": [
        "kemudian buat tf.keras.layers.StringLookup layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nSqr6z7Fp0uD"
      },
      "outputs": [],
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bq7vUzqp0rn",
        "outputId": "240e51eb-3703-48f5-b70f-80359410d90a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZY5gn1EEp8CQ"
      },
      "outputs": [],
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9u9I2e4qBU9",
        "outputId": "ccd25918-7e49-4586-fb37-5ccba1c754a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "chars = chars_from_ids(ids)\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H77qa8SbqD7r",
        "outputId": "924c0785-c17b-4d6b-9a15-0f017afa7274"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MDXm0r42qGZ9"
      },
      "outputs": [],
      "source": [
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WPflQITqJTt"
      },
      "source": [
        "Prediksi\n",
        "\n",
        "Membuat Training Set dan Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73kylzGkqNzs",
        "outputId": "f3bb9407-1cce-4d92-df3b-86bc47e7692b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Mj_BsixZqQN2"
      },
      "outputs": [],
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18iLIcipqTeS",
        "outputId": "7a5b67d3-b794-40b3-9c8f-327f357abb2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ],
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "p_MusSReqV7b"
      },
      "outputs": [],
      "source": [
        "seq_length = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFlcBAs3qYie"
      },
      "source": [
        "Metode batch memungkinkan kita dengan mudah mengonversi karakter individual ini menjadi urutan ukuran yang diinginkan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5xUrzBCqc27",
        "outputId": "b2f42fa6-5b03-4344-b959-0879a2200ef2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOQPgK8uqiJk"
      },
      "source": [
        "akan lebih mudah untuk melihat apa yang dilakukan jika Anda menggabungkan token kembali menjadi string:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSEJ5sg3qkQ4",
        "outputId": "5d5bfa8f-c91d-43f3-cb15-0fd9d4aeedd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ],
      "source": [
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9EocGhsqrKi"
      },
      "source": [
        "Untuk pelatihan, Anda memerlukan kumpulan data pasangan (input, label). Dimana input dan label merupakan urutan. Pada setiap langkah waktu, inputnya adalah karakter saat ini dan labelnya adalah karakter berikutnya. Berikut adalah fungsi yang mengambil urutan sebagai masukan, menduplikasi, dan menggesernya untuk menyelaraskan masukan dan label untuk setiap langkah waktu:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "F4i8yWAUqttL"
      },
      "outputs": [],
      "source": [
        "def split_input_target(sequence):\n",
        "  input_text = sequence[:-1]\n",
        "  target_text = sequence[1:]\n",
        "  return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdC60Yf3qw1R",
        "outputId": "c4a8e92d-2a9e-472a-9941-1d6e8a30dbe3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "KRzoiuyoqzvb"
      },
      "outputs": [],
      "source": [
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_RB-i84q2aX",
        "outputId": "43ade16a-5547-47a0-d6c2-d23cb25e9c54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ],
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "  print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "  print(\"Target:\", text_from_ids(target_example).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpyC3Lfdq409"
      },
      "source": [
        "Membuat Batch Training\n",
        "\n",
        "Anda menggunakan tf.data untuk membagi teks menjadi sequence yang dapat diatur. Namun sebelum memasukkan data ini ke dalam model, Anda perlu mengacak data dan mengemasnya ke dalam batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eh_3rr0Lq9T0",
        "outputId": "6d4d808e-09cf-43b5-d7e1-9974627c77ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vJDZHqOrA-D"
      },
      "source": [
        "Membuat Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "D07ADY4vq_oC"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "nFQJrvVvrIZ3"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "C6DmNDvArKjG"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiz4DeAdrMOC"
      },
      "source": [
        "Uji Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzrXbO1OrQZb",
        "outputId": "fac14542-af29-4657-9db7-d3ed60f782cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-v-FtDOYrSzE",
        "outputId": "c3928775-73d2-4aa4-9843-a293ce34c562"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "XZGijCaorWYx"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0],num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYQiByzarYt2",
        "outputId": "61f7a65b-1af4-4c28-a8c5-93c0eda1970c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0, 59, 22, 58, 24, 63, 45, 57, 38, 42, 28, 24, 14, 60, 61,  2,  0,\n",
              "       35, 31, 42, 27, 63, 50, 33,  3,  6, 60, 54,  1, 21, 43, 35, 43,  7,\n",
              "       36, 38, 41, 17, 14, 60, 40, 10, 22, 18, 25, 16, 60, 19,  1, 49, 63,\n",
              "       30, 29, 14, 40, 47, 48, 46, 56, 48, 27, 65, 46, 57, 53,  1, 52, 59,\n",
              "       60, 60, 23,  0, 21,  7, 44, 55,  0, 36, 26, 33, 59, 38, 45, 28, 54,\n",
              "        8, 23, 18, 52, 19, 49, 43, 31, 21, 16, 19, 21,  3,  4, 50])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sampled_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STcK2eldrbAm"
      },
      "source": [
        "Dekode kode berikut untuk melihat teks yang diprediksi oleh model tidak terlatih ini:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cY__Gc4rdqP",
        "outputId": "b5dadd6d-5af8-4863-a95e-8e5b712f10a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:\n",
            " b' my young lady asked for, the nurse cursed in\\nthe pantry, and every thing in extremity. I must\\nhence'\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"[UNK]tIsKxfrYcOKAuv [UNK]VRcNxkT!'uo\\nHdVd,WYbDAua3IELCuF\\njxQPAahigqiNzgrn\\nmtuuJ[UNK]H,ep[UNK]WMTtYfOo-JEmFjdRHCFH!$k\"\n"
          ]
        }
      ],
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIEvEEFprgx5"
      },
      "source": [
        "### **Train Model**\n",
        "\n",
        "Tambahan optimizer dan fungsi loss<p>\n",
        "\n",
        "loss function tf.keras.losses.sparse_categorical_crossentropy standar berfungsi dalam kasus ini karena diterapkan di seluruh dimensi terakhir prediksi. Karena model Anda mengembalikan logits, Anda perlu mengatur flag from_logits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "WEhpmrSIrl8x"
      },
      "outputs": [],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vQrRQy2roWv",
        "outputId": "a2724aeb-4971-427b-f2dc-d5f0151d5daf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.1897335, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtG_mI_lrqsC"
      },
      "source": [
        "Model yang baru diinisialisasi tidak boleh terlalu yakin dengan dirinya sendiri, semua log keluaran harus memiliki besaran yang sama. Untuk mengonfirmasi hal ini, Anda dapat memeriksa bahwa eksponensial dari loss rata-rata harus kira-kira sama dengan ukuran kosakata. Loss yang jauh lebih tinggi berarti model tersebut yakin akan jawaban yang salah, dan memiliki inisialisasi yang buruk:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuSW1aiirsyW",
        "outputId": "0dae3b11-4773-4d89-d3b1-9aba0bf892c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "66.0052"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Fc4lBWkrvV3"
      },
      "source": [
        "Konfigurasikan prosedur pelatihan menggunakan metode tf.keras.Model.compile. Gunakan tf.keras.optimizers.Adam dengan argumen default dan fungsi loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "jnGYrAQ5rxNU"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RD8-WonFr0EQ"
      },
      "source": [
        "Konfigurasi Checkpoints<p>\n",
        "Gunakan tf.keras.callbacks.ModelCheckpoint untuk memastikan bahwa checkpoint disimpan selama pelatihan:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "YpmA-Ncxr3nE"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFTJWDB8r6Di"
      },
      "source": [
        "Lakukan Proses Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAqUQUZCr7lR",
        "outputId": "7bd53f7c-988a-4506-f520-3bb1540a970a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "172/172 [==============================] - 26s 72ms/step - loss: 2.7143\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 11s 52ms/step - loss: 1.9802\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 11s 53ms/step - loss: 1.7010\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 11s 54ms/step - loss: 1.5414\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 1.4444\n",
            "Epoch 6/10\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.3771\n",
            "Epoch 7/10\n",
            "172/172 [==============================] - 12s 57ms/step - loss: 1.3251\n",
            "Epoch 8/10\n",
            "172/172 [==============================] - 13s 59ms/step - loss: 1.2802\n",
            "Epoch 9/10\n",
            "172/172 [==============================] - 14s 63ms/step - loss: 1.2392\n",
            "Epoch 10/10\n",
            "172/172 [==============================] - 13s 59ms/step - loss: 1.1990\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8sZbFFxsDM-"
      },
      "source": [
        "Generate Teks<p>\n",
        "\n",
        "Berikut ini membuat prediksi satu langkah:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "6QIyjnK5sGj3"
      },
      "outputs": [],
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "hToII-X0sIe8"
      },
      "outputs": [],
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzIiJubhsLF4",
        "outputId": "7c3c3c9d-373f-4fa5-bdaf-9a1b175f3323"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "Why, then, corn, my infate! no worth and kind!\n",
            "Why, and if I could tribune he wash, and where't\n",
            "Whreel you bright see in prison. Sir,\n",
            "That it should live out of transport;\n",
            "Where is all and subjects and am very person,\n",
            "With them one father, grow with a grable\n",
            "As if the grief commanders of otherss.\n",
            "\n",
            "PRINCE:\n",
            "Mark'd! speaking not which them from the house of Lancaster\n",
            "Were I there? Row, By this, Tybalt's son:\n",
            "My lord wish, I'll born waking to her youth\n",
            "I'll be fought with such assured suitor\n",
            "The slain wench daughter when I would buy whate he would\n",
            "Have a honey ground in their beheman:\n",
            "Draws Kate, and for exsent,--why, then we shall die.\n",
            "\n",
            "ISABELLA:\n",
            "\n",
            "Pedant:\n",
            "Which is upon thy spirate! spect all from the\n",
            "Bionhelacely, but one friend only, fallon!\n",
            "\n",
            "KING RICHARD III:\n",
            "What, who shall watch?\n",
            "\n",
            "FRIAR LAURENCE:\n",
            "Well, I not eppe hadft, some klented flesh;\n",
            "And therefore, Sition: for faults it is,\n",
            "Nuplefice.\n",
            "I'ld not here red them.\n",
            "\n",
            "WARWICK:\n",
            "Let me helm thee; and, as I teet am asking and bear-be-dead, \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.310788154602051\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zv4u765nsOBQ",
        "outputId": "45a1bcc7-030d-4dc1-95ce-0edfece1c151"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\nThere was not your comfort: you know the rest,\\nTo fake fortuna over-Come to Present at\\nWas do a swof thereby he is entertain\\nThan ship at entering and weepht whose ward's course,\\nI shall be borne to usage his country: take our numbering:\\nIt is a bed on me, then in sheets,\\nThe greatest eye, would you have.\\n\\nISABELLA:\\nLook, whereto you have the fairer best?' Thou shalt\\nTo think it not a slave, that are spectalone\\nTherebie, and married. How ere have not them?\\n\\nLADY CAPULET:\\nWell found is your face, nobly brotherly.\\n\\nFirst Setati:\\nYee, Sicilen, God, York!\\nShould entreat you of the fastal care of.\\n\\nBUCKINGHAM:\\nMadam, then they free what proclaim they better\\nit is not not to pardon to keeper.\\nThen let's mut power the shy so courteen of you.\\n\\nKING LEWIS XI VONUMNIA:\\nPeace Roman flotter, your sons,\\nWhen sink will not be to do meldied,\\nAnd when the city of this oxtance, alack, An image in earne\\nTo mourness frow war I have courtedy and rulber'd at the\\nworld.\\n\\nLADY CAPULET:\\nTold me humbles are p\"\n",
            " b\"ROMEO:\\nShe hably for my pame;\\nLead and watch thim world's very crown,\\nSo land will entertain my kinsman before them on\\nthe world, I shall be colsulet.\\n\\nMessenger:\\nArt thou, manow and Warwick quarrel.\\n\\nFirst Citizen:\\nAy,\\nconsider;\\nWhom course is lesser, that fools.\\nWere not so brought there: I am sorrow?\\nAccuse me from the fatal hand; I'll know your goodly\\ngentle sentence and the honour I'ld bread.\\n\\nNurse:\\nNow I know too walk of all, I would it not\\nUpon their back of gaintain's wife,\\nEnough him at the good tork! If it was purtuiting\\nThan the ground man the house doth good.\\nMercuful case, masters, touch them government to\\nour prevapies: young most deward Even to have\\nTownsmal and wanted the onator with any looks\\nBefore him or his friends, I see them use,\\nAnd cried Decending heavy verend all\\nSee-way'd in our course. You never sound dream,\\nWhence friends very noicuman.\\n\\nLEONTES:\\nIt was at hour by gaze.\\n\\nBIONDELLE:\\nLet's Sarconten.\\n\\nPETRUCHIO:\\nAlack there's us, and, so I trad?\\n\\nTYBALT:\\nThat as ha\"\n",
            " b\"ROMEO:\\nIt hast thou fowl'd modest spriam Jove's fear upon me.\\n\\nProvost:\\nHis which Claudio, with the wenderal sounder; the good is call them henour:\\nMore very face therein as it was by the gods,\\nWere I let them one twice of a word; Oxe or it.\\n\\nSBALY:\\nThen, Iffereth and ctreets the hall: you take it up to remembrance.\\nWhy, cover my tongue about immodeman's death?\\n\\nSecond Servant:\\nWill't not then my gentle Dorses can obstral\\nTo do what tronger'd by note-fulfility;\\nfor here had before thee had they she strives for winter't,\\nSome hang of kings and bring with him,\\nAnd deform the state of high begues to round.\\nFor death, whereood pehis and happiness:\\nThe rest o' the shadow have I not ave done,\\nAnd devility in combassion,\\nTo tell thou hast but sack down, and then\\nBe perform'd of his conjected,\\nAnd therefore quit we from me to the hand;\\nTo do you teach my jointinger. I must confess him,\\nBut since you undo leave to reple the goes\\nWinnow fill'd words coll the whilst I judge and gave his will?\\n\\nKING RIC\"\n",
            " b\"ROMEO:\\nNot so out; for,wed the\\nsport is caparing.\\n\\nSEBASTIAN:\\nI pardon them.\\n\\nLeONTES:\\nYour brother, patricians of Paris, do go all good.\\n\\nSecond Gentleman:\\nThey know the crows, which has a well of care, hand\\nOf stock Lances and in tremblous.\\n\\nKING RICHARD III:\\nWill have my consull so breathe have a true peace\\nAnd hearing jound of solicies:\\nBut rest then banishment by his honour:\\nMy lord,--the vaulty here for Richard,'\\nIntrift to call the sways of late's visage,\\nThe fatain disess as truths,\\nRepent in your tongue. And will you have a new-done\\nThat have my part and not to drews seven of the good part\\nWhat man 'sir, come you with the brother,\\nAnd remembering to furlo my apparel,\\nThan fair sister, your pawds and unprescisciance,\\nLaothes on the business, my proclamicition\\nTo't unfolmitsters! Dukes,\\nTo help his opinion, the composions sort\\nTo give him repause the cloats;\\nIt shall'd and set to me than for the\\nland surgened when he governed him to Thee\\nAnd un'tis gread tongue.\\n\\nPETRUCHIO:\\nPeace, Lor\"\n",
            " b\"ROMEO:\\nWell, hath I the supt of France to JoHO: to the ground match all;\\nAnd, for then, now for their ground\\nIn sppect of the suphor says, Lend it you to your wail,\\nWhere you are milks of his holk what treachery.\\nO, therefore, I pray you, Froth, I am courtier's good\\nHast their o'stain: 'Geas' service and Lord Hadward!\\nLord Hasting, beli'tt to extreme your ghost\\nUpon the heightood redument.\\n\\nROMEO:\\nHence, and I'll breathe, in God's name\\nMore voice of Lewis, he stands listenly as one hand.\\nThen were our desures for it; you will past\\nThe surprede groes and notmines for your beer,\\nMy present vengain youth, to way stole wars,\\nLest was he brief, toprightance of the opensy,\\nMore, good fathers, too thought this atter.\\n\\nDUKE VINCENTIO:\\nYour business ephe ordent, besides\\nAnd charm'd reprowded and give or his pomendy,\\nGreat warrwing and Seize from thee: not strange\\nRome tongue to the best of this.\\n\\nPadIN:\\nTrumpet; some offence! sound the lind upon't!\\nThe precious goddess is sedscance doth out as worthi\"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.7434918880462646\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6bVTZKcsQgs"
      },
      "source": [
        "Ekspor Model Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWcg3d0TsS6O",
        "outputId": "a25a1a67-9d45-40be-f87c-334d83c9e882"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7a1da71e0340>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKVK-r7usUlz",
        "outputId": "fbb01fc7-9d9a-49b0-f4f4-1d61b9ced48f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "Too well; then 'dovery's foolish wread on.\n",
            "\n",
            "ROMEO:\n",
            "Thou hast ansween togesher.'\n",
            "\n",
            "ROMEO:\n",
            "\n",
            "FLORIZEL:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3gu13D-ssAW"
      },
      "source": [
        "-----\n",
        "Tugas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "bM9r4DJZsvFS"
      },
      "outputs": [],
      "source": [
        "class CustomTraining(MyModel):\n",
        "  @tf.function\n",
        "  def train_step(self, inputs):\n",
        "    inputs, labels = inputs\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = self(inputs, training=True)\n",
        "      loss = self.loss(labels, predictions)\n",
        "      grads = tape.gradient(loss, model.trainable_variables)\n",
        "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "      return {'loss': loss}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "o-XO2DGysxNt"
      },
      "outputs": [],
      "source": [
        "model = CustomTraining(\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "pz-GX1zOszKz"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhqIxNvFs-4Y",
        "outputId": "6ca2842f-6aa4-4fbd-a62b-3fb476492806"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "172/172 [==============================] - 14s 58ms/step - loss: 2.7405\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a1d6ef92b00>"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(dataset, epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGwHLE94tEdQ",
        "outputId": "ae65f418-8372-45a6-c2bf-26b2bcfca9be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 2.1944\n",
            "Epoch 1 Batch 50 Loss 2.0967\n",
            "Epoch 1 Batch 100 Loss 1.9814\n",
            "Epoch 1 Batch 150 Loss 1.8533\n",
            "\n",
            "Epoch 1 Loss: 2.0056\n",
            "Time taken for 1 epoch 12.97 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 2 Batch 0 Loss 1.8469\n",
            "Epoch 2 Batch 50 Loss 1.7556\n",
            "Epoch 2 Batch 100 Loss 1.7251\n",
            "Epoch 2 Batch 150 Loss 1.6800\n",
            "\n",
            "Epoch 2 Loss: 1.7318\n",
            "Time taken for 1 epoch 11.95 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 3 Batch 0 Loss 1.6022\n",
            "Epoch 3 Batch 50 Loss 1.5833\n",
            "Epoch 3 Batch 100 Loss 1.5505\n",
            "Epoch 3 Batch 150 Loss 1.5136\n",
            "\n",
            "Epoch 3 Loss: 1.5681\n",
            "Time taken for 1 epoch 20.47 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 4 Batch 0 Loss 1.4609\n",
            "Epoch 4 Batch 50 Loss 1.4780\n",
            "Epoch 4 Batch 100 Loss 1.4744\n",
            "Epoch 4 Batch 150 Loss 1.4660\n",
            "\n",
            "Epoch 4 Loss: 1.4650\n",
            "Time taken for 1 epoch 11.20 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 5 Batch 0 Loss 1.4363\n",
            "Epoch 5 Batch 50 Loss 1.4176\n",
            "Epoch 5 Batch 100 Loss 1.3506\n",
            "Epoch 5 Batch 150 Loss 1.3486\n",
            "\n",
            "Epoch 5 Loss: 1.3944\n",
            "Time taken for 1 epoch 11.28 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 6 Batch 0 Loss 1.3437\n",
            "Epoch 6 Batch 50 Loss 1.3102\n",
            "Epoch 6 Batch 100 Loss 1.3213\n",
            "Epoch 6 Batch 150 Loss 1.3091\n",
            "\n",
            "Epoch 6 Loss: 1.3414\n",
            "Time taken for 1 epoch 11.29 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 7 Batch 0 Loss 1.3206\n",
            "Epoch 7 Batch 50 Loss 1.2814\n",
            "Epoch 7 Batch 100 Loss 1.2847\n",
            "Epoch 7 Batch 150 Loss 1.3463\n",
            "\n",
            "Epoch 7 Loss: 1.2960\n",
            "Time taken for 1 epoch 11.83 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 8 Batch 0 Loss 1.2277\n",
            "Epoch 8 Batch 50 Loss 1.2411\n",
            "Epoch 8 Batch 100 Loss 1.2523\n",
            "Epoch 8 Batch 150 Loss 1.2578\n",
            "\n",
            "Epoch 8 Loss: 1.2539\n",
            "Time taken for 1 epoch 12.62 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 9 Batch 0 Loss 1.2103\n",
            "Epoch 9 Batch 50 Loss 1.2517\n",
            "Epoch 9 Batch 100 Loss 1.2289\n",
            "Epoch 9 Batch 150 Loss 1.2665\n",
            "\n",
            "Epoch 9 Loss: 1.2149\n",
            "Time taken for 1 epoch 12.19 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 10 Batch 0 Loss 1.1576\n",
            "Epoch 10 Batch 50 Loss 1.1431\n",
            "Epoch 10 Batch 100 Loss 1.1444\n",
            "Epoch 10 Batch 150 Loss 1.1650\n",
            "\n",
            "Epoch 10 Loss: 1.1753\n",
            "Time taken for 1 epoch 11.32 sec\n",
            "________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "mean = tf.metrics.Mean()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  mean.reset_states()\n",
        "  for (batch_n, (inp, target)) in enumerate(dataset):\n",
        "    logs = model.train_step([inp, target])\n",
        "    mean.update_state(logs['loss'])\n",
        "\n",
        "    if batch_n % 50 == 0:\n",
        "      template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
        "      print(template)\n",
        "\n",
        "  # saving (checkpoint) the model every 5 epochs\n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "  print()\n",
        "  print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
        "  print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
        "  print(\"_\"*80)\n",
        "\n",
        "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjlntKy3tUJW"
      },
      "source": [
        "### **Jawaban Kesimpulan**\n",
        "\n",
        "Perbedaan antara kode tugas dengan praktikum 2 terletak pada prosedur pelatihan. Pada praktikum 2 menggunakan pendekatan pelatihan yang lebih sederhana dan umum digunakan, dengan model.fit. Sedangkan kode pada tugas menggambarkan pendekatan pelatihan yang lebih spesifik dan kompleks, yang dilakukan beberapa kustomisasi.<p>\n",
        "\n",
        "Dalam pendekatan ini, mendefinisikan metode train_step dalam model turunan yang mengatur pelatihan pada tingkat batch. Secara eksplisit dilakukan perhitungan loss, gradien, dan menerapkan pembaruan bobot model dengan apply_gradients, serta menggunakan objek tf.metrics.Mean untuk menghitung rata-rata loss selama pelatihan. Pendekatan ini memberikan lebih banyak kontrol dan fleksibilitas dalam pengaturan pelatihan model."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
