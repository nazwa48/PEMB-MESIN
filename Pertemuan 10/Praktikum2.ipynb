{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pA1JZimYf9j8"
      },
      "source": [
        "# **Praktikum 2**\n",
        "Generator Teks dengan RNN<p>\n",
        "\n",
        "Praktikum ini mendemonstrasikan cara melakukan genearsi text menggunakan RNN. Dataset yang digunkan adalah dataset Shakespeare's writing from Andrej Karpathy's The Unreasonable Effectiveness of Recurrent Neural Networks. Jika diberikan urutan karakter dari data ini (\"Shakespear\"), latih model untuk memprediksi karakter berikutnya dalam urutan (\"e\"). Urutan teks yang lebih panjang dapat dihasilkan dengan memanggil model berulang kali.<p>\n",
        "Note: Enable GPU acceleration to execute this notebook faster. In Colab: Runtime > Change runtime type > Hardware accelerator > GPU.<p>\n",
        "Tutorial ini menggunakan tf.keras dan eager execution. Berikut adalah contoh output ketika model dalam tutorial ini dilatih selama 30 epoch, dan dimulai dengan prompt \"Q\":\n",
        "\n",
        "```dart\n",
        "QUEENE:\n",
        "I had thought thou hadst a Roman; for the oracle,\n",
        "Thus by All bids the man against the word,\n",
        "Which are so weak of care, by old care done;\n",
        "Your children were in your holy love,\n",
        "And the precipitation through the bleeding throne.\n",
        "\n",
        "BISHOP OF ELY:\n",
        "Marry, and will, my lord, to weep in such a one were prettiest;\n",
        "Yet now I was adopted heir\n",
        "Of the world's lamentable day,\n",
        "To watch the next way with his father with his face?\n",
        "\n",
        "ESCALUS:\n",
        "The cause why then we are all resolved more sons.\n",
        "\n",
        "VOLUMNIA:\n",
        "O, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, it is no sin it should be dead,\n",
        "And love and pale as any will to that word.\n",
        "\n",
        "QUEEN ELIZABETH:\n",
        "But how long have I heard the soul for this world,\n",
        "And show his hands of life be proved to stand.\n",
        "\n",
        "PETRUCHIO:\n",
        "I say he look'd on, if I must be content\n",
        "To stay him from the fatal of our country's bliss.\n",
        "His lordship pluck'd from this sentence then for prey,\n",
        "And then let us twain, being the moon,\n",
        "were she such a case as fills m\n",
        "```\n",
        "\n",
        "Meskipun beberapa kalimat memiliki tata bahasa, sebagian besar tidak masuk akal. Model belum mempelajari arti kata-kata, namun anggap saja:\n",
        "\n",
        "### **Setup**\n",
        "**Import TensorFlow**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bwOVruvCgThx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RILtKxGBg-Xp"
      },
      "source": [
        "### **Download Dataset Shakespeare**\n",
        "Sesuaikan dengan lokasi data yang Anda punya."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2WGOa9lf9Ai",
        "outputId": "b33ef436-deeb-4e5b-e969-9f0686fbaab6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 1s 1us/step\n"
          ]
        }
      ],
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XRLUvr9h_vl"
      },
      "source": [
        "## **Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QENtAhfPh6zE",
        "outputId": "785fcaae-58ac-47ca-f1da-28efd515ed29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ],
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swUB9fIoifKV",
        "outputId": "8f60fb61-f859-4f0d-f143-8d7eb89a67c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yoNMW_Wig2N",
        "outputId": "6402e44c-aa01-4d52-b8cf-da5572cdb028"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65 unique characters\n"
          ]
        }
      ],
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaFqTSKYijiE"
      },
      "source": [
        "### **Olah Teks**\n",
        "**Vectorize Teks**<p>\n",
        "Sebelum training, Anda perlu mengonversi string menjadi representasi numerik. tf.keras.layers.StringLookup dapat mengubah setiap karakter menjadi ID numerik. Caranya adalah teks akan dipecah menjadi token terlebih dahulu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CSEN__VipRx",
        "outputId": "27e8feb6-2184-4653-fc60-d61132154fc5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "\n",
        "example_texts = ['abcdefg', 'xyz']\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_NFFrXUiwCQ"
      },
      "source": [
        "sekarang buat tf.keras.layers.StringLookup layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QK4KfkIJix89"
      },
      "outputs": [],
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLGprga3i5A_"
      },
      "source": [
        "perintah diatas mengconvert token menjadi id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PMNcmuIi6jX",
        "outputId": "b6d184f3-4b6f-48aa-c841-bc22ffa0511f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1L3KY6QjL6M"
      },
      "source": [
        "Karena tujuan tutorial ini adalah untuk menghasilkan teks, penting juga untuk membalikkan representasi ini. Untuk ini Anda dapat menggunakan kode tf.keras.layers.StringLookup(..., invert=True).<p>\n",
        "Catatan: pada kode ini, daripada meneruskan kosakata asli yang dihasilkan dengan diurutkan(set(teks)) gunakan metode get_vocabulary() dari tf.keras.layers.StringLookup sehingga token [UNK] disetel dengan cara yang sama."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5ABrIHtJjOfA"
      },
      "outputs": [],
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ef8vM5LjR1H"
      },
      "source": [
        "Lapisan ini mengconvert kembali karakter dari vektor ID, dan mengembalikannya sebagai karakter tf.RaggedTensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZtOgc_GjTbc",
        "outputId": "f292cdc4-851c-4692-d1a8-73f9e43e44c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NEDIKFJjW8m"
      },
      "source": [
        "Anda dapat menggunakan tf.strings.reduce_join untuk menggabungkan kembali karakter menjadi string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2UXMiiwjixN",
        "outputId": "3522c6f1-ec7f-44e6-8a44-b679f4b4a3de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "g6g_GjuZkA7E"
      },
      "outputs": [],
      "source": [
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMI6B0mHjhTv"
      },
      "source": [
        "### **Prediksi**\n",
        "\n",
        "Diberikan sebuah karakter, atau serangkaian karakter, karakter apa yang paling mungkin berikutnya? Ini adalah tugas yang harus Anda latih agar model dapat melakukannya. Masukan ke model akan berupa urutan karakter, dan Anda melatih model untuk memprediksi keluaran berupa karakter berikut pada setiap langkah waktu. Karena RNN mempertahankan keadaan internal yang bergantung pada elemen yang terlihat sebelumnya, mengingat semua karakter dihitung hingga saat ini, karakter apa selanjutnya?\n",
        "\n",
        "**Membuat Trianing Set dan Target**<p>\n",
        "Selanjutnya bagilah teks menjadi contoh sequence. Setiap masukan sequence akan berisi karakter seq_length dari teks. Untuk setiap masukan sequence, target prediksi berisi teks dengan panjang yang sama, hanya digeser satu karakter ke kanan. Jadi, bagi teks menjadi beberapa bagian seq_length+1. Misalnya, seq_length adalah 4 dan teks kita adalah \"Hello\". Urutan masukannya adalah \"Hell\", dan urutan targetnya adalah \"ello\". Untuk melakukan ini, pertama-tama gunakan fungsi tf.data.Dataset.from_tensor_slices untuk mengonversi vektor teks menjadi aliran indeks karakter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlBiH_1VkYjV",
        "outputId": "a05dc3c4-53c1-4acf-ced4-0b5446816abd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bEe_fgwnkdU_"
      },
      "outputs": [],
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ww9qQpVdkgcs",
        "outputId": "95b1912a-f118-4830-9e59-419a3fba5a1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ],
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EZ35IfiEkiix"
      },
      "outputs": [],
      "source": [
        "seq_length = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3RWeWiJkk3D"
      },
      "source": [
        "Metode batch memungkinkan Anda dengan mudah mengonversi karakter individual ini menjadi urutan ukuran yang diinginkan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLLsY4QxkmLm",
        "outputId": "c999d1b8-980d-48cd-8c03-34a635ea52c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYnqkGBqkoq5"
      },
      "source": [
        "akan lebih mudah untuk melihat apa yang dilakukan jika Anda menggabungkan token kembali menjadi string:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWIJMkFMlVs2",
        "outputId": "91d0aa45-be61-433f-a2ff-87fe87b674d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ],
      "source": [
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nsugUR-labL"
      },
      "source": [
        "Untuk pelatihan, Anda memerlukan kumpulan data pasangan (input, label). Dimana input dan label merupakan urutan. Pada setiap langkah waktu, inputnya adalah karakter saat ini dan labelnya adalah karakter berikutnya. Berikut adalah fungsi yang mengambil urutan sebagai masukan, menduplikasi, dan menggesernya untuk menyelaraskan masukan dan label untuk setiap langkah waktu:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Oeezn74glcyD"
      },
      "outputs": [],
      "source": [
        "def split_input_target(sequence):\n",
        "  input_text = sequence[:-1]\n",
        "  target_text = sequence[1:]\n",
        "  return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_yPgsUWle_8",
        "outputId": "98ce7987-fd93-4224-b40d-3bb56fb95cd6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "CidrL0lVlgj_"
      },
      "outputs": [],
      "source": [
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPQ-cfIolk05",
        "outputId": "2dd7a69c-8ad9-419f-db5b-8560e9f301a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ],
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "  print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "  print(\"Target:\", text_from_ids(target_example).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzhIRviklp3Q"
      },
      "source": [
        "### **Membuat Batch Training**\n",
        "Anda menggunakan tf.data untuk membagi teks menjadi sequence yang dapat diatur. Namun sebelum memasukkan data ini ke dalam model, Anda perlu mengacak data dan mengemasnya ke dalam batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_Gp3k47ltc-",
        "outputId": "2e2c75e0-6d36-4fb8-b499-21d0d0269883"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9Mrbp3vlwLs"
      },
      "source": [
        "### **Buat Model**\n",
        "\n",
        "Bagian ini mendefinisikan model sebagai subkelas keras.Model (untuk lebih detilnya, lihat Making new Layers and Models via subclassing).<p>\n",
        "Model yang kita bangun memiliki 3 lapisan neural network :\n",
        "- tf.keras.layers.Embedding: Lapisan masukan. Tabel pencarian yang dapat dilatih yang akan memetakan setiap karakter-ID ke vektor dengan dimensi embedding_dim;\n",
        "- tf.keras.layers.GRU: lapisan RNN dengan ukuran unit=rnn_units (Anda juga dapat menggunakan lapisan LSTM di sini.)\n",
        "- tf.keras.layers.Dense: Lapisan keluaran, dengan keluaran vocab_size. Ini menghasilkan satu logit untuk setiap karakter dalam kosakata. Ini adalah log kemungkinan setiap karakter menurut model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "aCybqmqLl7lT"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "agbpoAqpl9sO"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ZxVtYS6vl_lD"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1wWT5SfmDK3"
      },
      "source": [
        "Untuk setiap karakter, model mencari penyematan, menjalankan GRU satu langkah waktu dengan penyematan sebagai masukan, dan menerapkan dense layer untuk menghasilkan log yang memprediksi kemungkinan log karakter berikutnya:<p>\n",
        "\n",
        "<img src = \"https://raw.githubusercontent.com/tensorflow/text/master/docs/tutorials/images/text_generation_training.png\"><p>\n",
        "\n",
        "Note: Untuk pelatihan Anda bisa menggunakan model keras.Sequential di sini. Untuk menghasilkan teks nanti, Anda harus mengelola status internal RNN. Akan lebih mudah untuk memasukkan opsi input dan output status di awal, daripada mengatur ulang arsitektur model nanti. untuk detailnya bisa dilihat Keras RNN guide.\n",
        "\n",
        "### **Uji Model**\n",
        "Coba jalankan model dan cek apakah sidah sesuai dengan output\n",
        "pertama, cek bentuk dari output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpquASdEmbzS",
        "outputId": "a6b78d09-f64d-4f5c-c5c2-9928b83a4b7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmldwSBtmf98"
      },
      "source": [
        "Dalam contoh di atas, panjang urutan masukan adalah 100 tetapi model dapat dijalankan pada masukan dengan panjang berapa pun:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4p8PdlkmhZp",
        "outputId": "5d9adf32-262d-4572-8590-fe6400cdc0c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kB8iTYAomjr0"
      },
      "source": [
        "Untuk mendapatkan prediksi aktual dari model, Anda perlu mengambil sampel dari distribusi keluaran, untuk mendapatkan indeks karakter aktual. Distribusi ini ditentukan oleh logit pada kosakata karakter. Catatan: Penting untuk mengambil sampel dari distribusi ini karena mengambil argmax dari distribusi tersebut dapat dengan mudah membuat model terjebak dalam infinote loop. Cobalah untuk contoh pertama di batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "rmswLGKOmlQv"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0],num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHLCZ1bSmp8P"
      },
      "source": [
        "Hal ini memberi kita, pada setiap langkah waktu, prediksi indeks karakter berikutnya:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sw23e_ilm1TF",
        "outputId": "dabbff12-788f-4211-ac9b-72de0eca44f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([15, 32,  7,  8, 21, 13, 32, 31,  5, 39, 63, 31, 24, 37, 65, 50, 50,\n",
              "       50, 11, 26, 64, 19, 46, 26, 61, 10, 21, 30, 31, 64,  2, 23,  7, 41,\n",
              "       50, 26, 32, 42, 63, 26, 65, 65, 25, 47, 17, 35,  6, 53, 26, 41, 35,\n",
              "       14, 16, 61, 35, 41, 12, 36, 51, 17, 27, 38, 46, 17, 26, 57, 53, 59,\n",
              "       47, 43, 24, 44, 28, 21, 57, 44, 48, 33,  4, 30, 42, 43, 15, 46, 32,\n",
              "       43, 34, 53, 15, 22, 60, 27, 42, 37, 26, 13, 59, 21, 48, 12])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "sampled_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i70bI0ism4Ac"
      },
      "source": [
        "Dekode kode berikut untuk melihat teks yang diprediksi oleh model tidak terlatih ini:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dle-lW8vm5tC",
        "outputId": "7439615d-6030-4a8e-c411-e64287874a4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b'RCUTIO:\\nNay, an there were two such, we should have none\\nshortly, for one would kill the other. Thou'\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"BS,-H?SR&ZxRKXzkkk:MyFgMv3HQRy J,bkMScxMzzLhDV'nMbVACvVb;WlDNYgDMrnthdKeOHreiT$QcdBgSdUnBIuNcXM?tHi;\"\n"
          ]
        }
      ],
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A5HINuem-qK"
      },
      "source": [
        "### **Train Model**\n",
        "Pada titik ini permasalahan dapat dianggap sebagai permasalahan klasifikasi standar. Permasalahan dapat disimpulkan dengan : Berdasarkan status RNN sebelumnya, dan masukan langkah kali ini, prediksi kelas karakter berikutnya.<p>\n",
        "\n",
        "**Tambahan optimizer dan fungsi loss**<p>\n",
        "\n",
        "loss function tf.keras.losses.sparse_categorical_crossentropy standar berfungsi dalam kasus ini karena diterapkan di seluruh dimensi terakhir prediksi. Karena model Anda mengembalikan logits, Anda perlu mengatur flag from_logits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "sAuRxCWdnKTE"
      },
      "outputs": [],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5cY7opBnSHB",
        "outputId": "62c91d28-6021-433e-ffb3-f5ba5d880d63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.190146, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYs0aHcnnUDB"
      },
      "source": [
        "Model yang baru diinisialisasi tidak boleh terlalu yakin dengan dirinya sendiri, semua log keluaran harus memiliki besaran yang sama. Untuk mengonfirmasi hal ini, Anda dapat memeriksa bahwa eksponensial dari loss rata-rata harus kira-kira sama dengan ukuran kosakata. Loss yang jauh lebih tinggi berarti model tersebut yakin akan jawaban yang salah, dan memiliki inisialisasi yang buruk:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMvQ-yZDnVcy",
        "outputId": "a249a9a7-9aca-4e9e-ab2c-bde9485b6b08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66.032425"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAVnuE-BnX3T"
      },
      "source": [
        "Konfigurasikan prosedur pelatihan menggunakan metode tf.keras.Model.compile. Gunakan tf.keras.optimizers.Adam dengan argumen default dan fungsi loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "KX_URPUMnZqZ"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',loss=loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_cVUCDmne85"
      },
      "source": [
        "### **Konfigurasi Checkpoints**\n",
        "Gunakan tf.keras.callbacks.ModelCheckpoint untuk memastikan bahwa checkpoint disimpan selama pelatihan:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "wj3uCCY_ni_-"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Dd2TQ4anlab"
      },
      "source": [
        "### **Lakukan Proses Training**\n",
        "Agar waktu pelatihan tidak terlalu lama, gunakan 10 epoch untuk melatih model. Di Colab, setel runtime ke GPU untuk pelatihan yang lebih cepat."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "2aLuZh7cno8H"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoayQKVrn2jf",
        "outputId": "1e9020c7-761c-4c14-8320-8cf1cc4e6dce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "172/172 [==============================] - 14s 53ms/step - loss: 2.7164\n",
            "Epoch 2/20\n",
            "172/172 [==============================] - 11s 52ms/step - loss: 1.9924\n",
            "Epoch 3/20\n",
            "172/172 [==============================] - 11s 54ms/step - loss: 1.7190\n",
            "Epoch 4/20\n",
            "172/172 [==============================] - 15s 68ms/step - loss: 1.5585\n",
            "Epoch 5/20\n",
            "172/172 [==============================] - 13s 55ms/step - loss: 1.4590\n",
            "Epoch 6/20\n",
            "172/172 [==============================] - 11s 53ms/step - loss: 1.3895\n",
            "Epoch 7/20\n",
            "172/172 [==============================] - 11s 53ms/step - loss: 1.3356\n",
            "Epoch 8/20\n",
            "172/172 [==============================] - 11s 53ms/step - loss: 1.2916\n",
            "Epoch 9/20\n",
            "172/172 [==============================] - 12s 53ms/step - loss: 1.2512\n",
            "Epoch 10/20\n",
            "172/172 [==============================] - 11s 54ms/step - loss: 1.2110\n",
            "Epoch 11/20\n",
            "172/172 [==============================] - 11s 53ms/step - loss: 1.1717\n",
            "Epoch 12/20\n",
            "172/172 [==============================] - 12s 53ms/step - loss: 1.1318\n",
            "Epoch 13/20\n",
            "172/172 [==============================] - 12s 54ms/step - loss: 1.0892\n",
            "Epoch 14/20\n",
            "172/172 [==============================] - 11s 54ms/step - loss: 1.0443\n",
            "Epoch 15/20\n",
            "172/172 [==============================] - 11s 54ms/step - loss: 0.9967\n",
            "Epoch 16/20\n",
            "172/172 [==============================] - 11s 54ms/step - loss: 0.9465\n",
            "Epoch 17/20\n",
            "172/172 [==============================] - 11s 54ms/step - loss: 0.8941\n",
            "Epoch 18/20\n",
            "172/172 [==============================] - 12s 54ms/step - loss: 0.8409\n",
            "Epoch 19/20\n",
            "172/172 [==============================] - 12s 54ms/step - loss: 0.7883\n",
            "Epoch 20/20\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 0.7375\n"
          ]
        }
      ],
      "source": [
        "history=model.fit(dataset,epochs=EPOCHS,callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-78lVfFoo8k"
      },
      "source": [
        "### **Generate Teks**\n",
        "\n",
        "Cara termudah untuk menghasilkan teks dengan model ini adalah dengan menjalankannya dalam loop, dan menyimpan status internal model saat Anda menjalankannya.<p>\n",
        "\n",
        "<img src = \"https://raw.githubusercontent.com/tensorflow/text/master/docs/tutorials/images/text_generation_sampling.png\"><p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s75-_800o1mH"
      },
      "source": [
        "Setiap kali Anda memanggil model, Anda memasukkan beberapa teks dan state internal. Model mengembalikan prediksi untuk karakter berikutnya dan state barunya. Masukkan kembali prediksi dan state ke model untuk terus menghasilkan teks.<p>\n",
        "\n",
        "Berikut ini membuat prediksi satu langkah:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "6NsWLf39o45E"
      },
      "outputs": [],
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "0cuRSdUKo6i3"
      },
      "outputs": [],
      "source": [
        "one_step_model=OneStep(model,chars_from_ids,ids_from_chars)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBiLabljo8Gb"
      },
      "source": [
        "Jalankan secara berulang untuk menghasilkan beberapa teks. Melihat teks yang dihasilkan, Anda akan melihat model mengetahui kapan harus menggunakan huruf besar, membuat paragraf, dan meniru kosakata menulis seperti Shakespeare. Karena sedikitnya jumlah epoch pelatihan, model belum belajar membentuk kalimat runtut."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJ0GsvmPo9Xe",
        "outputId": "e94c151d-07d6-40b9-942f-de9d690de455"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "He recussing on no thing you so, so rid I see\n",
            "By many deees creating an urghamply.\n",
            "Care Glue is serve, use you: uscape of let him die.\n",
            "\n",
            "LEONTES:\n",
            "How! go thy daughter;\n",
            "And, Bour, I king not in my good lord.\n",
            "\n",
            "CORIOLANUS:\n",
            "You have rich'd\n",
            "That Minates shall pinch the bending disperse To beg\n",
            "Of friend an eptal cold, and stay thee, thankly,\n",
            "What man thou wasp'd, and defy my inhaties,\n",
            "Whose honourable death is done,\n",
            "For I have time to wie fieres, and your black music?\n",
            "Hark our lands, there were cherribling instantly,\n",
            "I here recove' no hate, in his natural,\n",
            "setuleties were pretend to speak of call this black.\n",
            "What, no, any think it is she straight:\n",
            "The dare not in think should be in him.\n",
            "But yet my leting not--Gentleman:\n",
            "Well, deaf cousin Buckingham.\n",
            "Then madam, but hold you for him?\n",
            "\n",
            "Citizens:\n",
            "My times Romeo to!\n",
            "\n",
            "AUFIDIUS:\n",
            "Ay, my lord.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "He rentle and happily we cheques it;\n",
            "In all my heart will to you make them thereof:\n",
            "Here in this craven Rost and all these mildrench-leather  \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.3362796306610107\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4BvlfvepAhX"
      },
      "source": [
        "Hal termudah yang dapat Anda lakukan untuk meningkatkan hasil adalah dengan melatihnya lebih lama (coba EPOCHS = 30). Anda juga dapat bereksperimen dengan string awal yang berbeda, mencoba menambahkan lapisan RNN lain untuk meningkatkan akurasi model, atau menyesuaikan parameter suhu untuk menghasilkan prediksi yang kurang lebih acak.<p>\n",
        "Jika Anda ingin model menghasilkan teks lebih cepat, hal termudah yang dapat Anda lakukan adalah membuat teks secara batch. Pada contoh di bawah, model menghasilkan 5 keluaran dalam waktu yang hampir sama dengan waktu yang dibutuhkan untuk menghasilkan 1 keluaran di atas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lLGIhHIpASq",
        "outputId": "aec79426-b36f-4f7e-d4e3-c4fd8b888717"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\nI have heard the sequeltry of RucenSio?\\n\\nBAPTISTA:\\n\\nKATHARINA:\\nWhat is about to curse that raim that man made it to the maid which he offended,\\nOur purpose will it be my joy!\\n\\nRICHMOND:\\nFellow, you was, and whos the raw!\\nWhat you have flowers to put and so please myself\\nLook you shall blue the lain while here once.\\n\\nDUCHESS OF YORK:\\nO, my arrest free, a husband!\\nYou might live us here stand upit.\\nThis stirral well? Who is't thou canst not live?\\n\\nGREMIO:\\n\\nKATHARINA:\\nCome, come, you are welcome 's, as hails\\nThat late more favour worms. What I shall die,\\nWith all the houses of his usual high wolvis\\nThou darest ventmuct; the air from his blood is here\\nto-day? my lord is grown inquire a lady:\\nThat should be so, let thou devised me\\nRicherboy this allow is flat; the son.\\n\\nISABELLA:\\nIs it upon my liege, the mother of your needing-shoots,\\nI did not light a sumple buy the down.\\n\\nLEONTES:\\nJove he that murderers move.\\n\\nBUCKINGHAM:\\nMadam, I frame you need that murders me.\\n\\nPETRUCHIO:\\nThou hast mor\"\n",
            " b\"ROMEO:\\nHe that kill'd him?\\n\\nBUCKINGHAM:\\nTut, I reconcile me to keep you till\\nThese honours in his east? He talk'd as ill behove\\nI never dishing true out a single, till\\nA holy fine shein ours, Angelo, upon thy bond\\nHath thou neglect my Richmond wrong'd, conamiled,\\nThat makes them for them to you. Lords,\\nRather than deny her truth of good to begin.\\n\\nWARWICK:\\nNo, he stoop and favour; and my heart love,\\nMust itself in zantua usure,\\nThat Romeo burst her brother, then, for York, and much\\nWere he that suffer our dismal heirs affect.\\n\\nLUCENTIO:\\nHere, madam:\\n'Tis very true:\\nI am the heavy offer; it is a grattenation\\nof your high impertiencent and gardens\\nDore live-sadutuared with your kindred thence!\\nOnce more imagination where I shall come to you.\\nLot on my heart thither seed thy son Paris and\\nDidst thou lean to to you that hor mocking.\\n\\nVINCENTIO:\\nI would thou draw to Menney with my tale perfamed\\nFor this shall answer it.\\n\\nAUTOLYCUS:\\nAnd what thyself into some man shall say a husband tells;\\nOur tra\"\n",
            " b\"ROMEO:\\nThe field by Time's mother, by\\nA thousand men? pursuen me in thy loss:\\nUthereos, we were by this despite, by me,\\nCamertinous Bolingbroke.\\n\\nLord:\\nCamillo, went thou diest; so you shall have the match.\\n\\nGREMIO:\\nHow often had rather hear my lord.\\n\\nDUKE VINCENTIO:\\nOf griefosted times after this late\\nIs prosperon by using paints, but have mode it\\nOr helcome with a rich of baits my wife.\\n\\nANTIGONUS:\\nAnd I know how thou hast not worth\\nAs to be to see the ministerhed bodg.\\n\\nYORK:\\nIf thy you infected wivors? why do you best me,\\nHe doth it prosent and braved myself again,\\nIs courtier' delivered help from loss,\\nThe life-burged report more patience.\\nBut now I tell thee, kepatian; lay do not\\nproceed.\\n\\nISABELL:\\n'Tis a woman woman.\\n\\nBUCKINGHAM:\\nI thank thee. Come, while we go tell me to myself\\nUnto his liberty is.\\n\\nLADY ANNE:\\nThuss' does to your brother, to get you to your womb;\\nElse, will't people--words, dress'd, to speak.\\nGood south whose bloody suits of brother out\\nMy soul methinks: I will unto \"\n",
            " b\"ROMEO:\\nPetrous to make a lord assailed. Now, good sir!\\n\\nPETRUCHIO:\\nAnd you,--\\n\\nSEBASTIAN:\\nNow! may, I see.\\n\\nThird Citizen:\\nFor this did I must give; the goddan men is yet?\\nAnd, as thou livest me, think of my born!\\n\\nYORK:\\nAt thy royal seet, whose heavenly say he lies,\\nSend for me at patience breeding.\\n\\nISABELLA:\\nLet me desire you that love.\\n\\nBAPTISTA:\\nNow, by the horses, off with him.\\n\\nBoth:\\nWell hear the harmon, of what jest worse?\\n\\nNORTHUMBERLAND:\\nThere is a friend ornament persuaded.\\n\\nGREMIO:\\nHere's soung'--\\n\\nQUEEN ELIZABETH:\\nHrown'd, awaked, for Edward.\\nERISelf,\\nSo to help, kindred, if true go we Credit his fond execution,\\nAs this lass expedility or nonestles with\\nhim: sent to be no bitter: whose hap that To keep off\\ngrief out another fondy words to wind after.\\nIs\\nthere thou art.\\n\\nHENRY BOLINGBROKE:\\nOf much that do I frame thyself,\\nThat I might love as many most richly done,\\nThat Edward is our blood were an hundred pispose.\\n\\nLADY ROSS:\\nThese arms of calm, the victory\\nWhose dead mainers of\"\n",
            " b\"ROMEO:\\nWhere let him thus; 'tis any goods be gone,\\nThat or be dult, wife, most days\\nUpon his man; his unclast robbery top of freedess\\nBy vain. Till that goes worm my legs,\\nBeing one that all his witcherd?\\n\\nLADY ANNE:\\nIs't ploused in justice, joling with my\\nstrange lords, because the triump may\\nAs he like a wencifflith in the tomb,\\nNo more that makes this sun uspect me straight.\\n\\nYORK:\\nOne who procips of cutrion of Vienna,\\nWhere thou directivest mine enemies to his\\nhands, as we can, instancy and gentlemen,\\nThat low on breathing death unto mine eye\\nsee how I would say. We will home to bed.\\n\\nBENVOLIO:\\nGo with him.\\n\\nCAMILLO:\\nO you will; for nothing affection?\\nHow lies he? ne'er have cause to vent\\nO' the senate and bring it, that was done to Edward:\\nHe hath thy death-burit man, my lady's womb and\\nto you. Fry you hear him? here comes the time will rublish'd with the\\ncreating: I have brought you that for you both.\\n\\nJULIET:\\nAy, but these large ears, and she Kathard.\\nIn sett forth I never speak with \"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.391263008117676\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuE7o-E2pGzi"
      },
      "source": [
        "### **Ekspor Model Generator**\n",
        "Model satu langkah ini dapat dengan mudah disimpan dan digunakan kembali, memungkinkan Anda menggunakannya di mana pun tf.saved_model diterima."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMptLykppKBs",
        "outputId": "ea6c715e-a3dd-4edc-83c8-50162ca97b8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x785c013ffd90>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1evxxnz5pLQI",
        "outputId": "fdab4ec9-e092-49b7-bdbb-2a0fe0ec6bb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "Pity, poison; for our enemies?\n",
            "\n",
            "Citizens:\n",
            "Done, let us all.\n",
            "\n",
            "ANTIGONUS:\n",
            "I know he.\n",
            "\n",
            "CAPULET:\n",
            "Go to,\n"
          ]
        }
      ],
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}